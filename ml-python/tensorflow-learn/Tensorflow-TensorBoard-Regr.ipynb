{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mpl_toolkits\n",
    "#from mpl_toolkits.mpot3d import Axes3D\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as  tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model \n",
    "\n",
    "\n",
    "$y(x) = a + b_1 * X_1 + b_2*X_2 + b_3*X_3 + \\sigma \\epsilon$\n",
    "\n",
    "$\\epsilon \\approx N(0,1)$\n",
    "\n",
    "$b_1, b_2, b_3 = (0.5, 0.2, 0.1) $\n",
    "\n",
    "$\\sigma=0.1$\n",
    "\n",
    "\n",
    "$X_1, X_2, X_3$ uniformally distributed in [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate Data\n",
    "\n",
    "n_points = 5000\n",
    "n_features = 3\n",
    "\n",
    "bias = np.ones(n_points).reshape((-1,1))\n",
    "low  = -1 * np.ones((n_points, n_features),dtype='float')\n",
    "high  = np.ones((n_points, n_features),dtype='float')\n",
    "\n",
    "#similated Features\n",
    "X =  np.random.uniform(low=low, high=high)\n",
    "\n",
    "\n",
    "#simulated Noise\n",
    "noise = np.random.normal(size=(n_points,1))\n",
    "\n",
    "#outputr\n",
    "weights = np.array([1.0, 0.5, 0.2, 0.1])\n",
    "noise_std = 0.1\n",
    "\n",
    "Y = weights[0] * bias + np.dot(X, weights[1:] .reshape(-1,1)) + noise_std * noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.15781829,  0.13063534,  0.74025826],\n",
       "       [ 0.28604545, -0.97095358, -0.57869739],\n",
       "       [ 0.47870732,  0.07846252,  0.84635806],\n",
       "       ..., \n",
       "       [ 0.94591511, -0.86843918,  0.13608197],\n",
       "       [ 0.41194819, -0.01217022, -0.6760082 ],\n",
       "       [ 0.31758177,  0.87903769,  0.37626833]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View X\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.10968022],\n",
       "       [ 0.89234434],\n",
       "       [ 1.34779366],\n",
       "       ..., \n",
       "       [ 1.24371334],\n",
       "       [ 1.13320279],\n",
       "       [ 1.33009926]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Y\n",
    "print(Y.shape)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data into train and test sets\n",
    "train_test_split = 4\n",
    "\n",
    "n_test = int(n_points/train_test_split)\n",
    "n_train = n_points - n_test\n",
    "\n",
    "X_train = X[:n_train, :]\n",
    "Y_train = Y[:n_train].reshape((-1,1))\n",
    "\n",
    "X_test = X[n_train:,:]\n",
    "Y_test = Y[n_train:].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1250, 3), (1250, 1), (3750, 3), (3750, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape, X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.placeholder(dtype, shape=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can do directly - but let us use Minibatch GRadient Descent\n",
    "#tf.placeholder(dtype, shape=None, name=None)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1) , name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_features + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = 2.0/n_train * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate* gradients)\n",
    "\n",
    "#Then define the batch size and compute the number of batches\n",
    "#batch_size = 100\n",
    "#n_batches  = np.ceil(n_test, batch_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00069797],\n",
       "       [ 0.47194025],\n",
       "       [ 0.17396879],\n",
       "       [ 0.11091298]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.001],\n",
       "       [ 0.028],\n",
       "       [ 0.026],\n",
       "       [-0.011]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diff from actual \n",
    "np.round(weights.reshape(-1,1) - best_theta,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-20180805063540/'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualizing Using the tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "#'tf_logs/run-20180805063540/'\n",
    "\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1) , name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_features + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = 2.0/n_train * tf.matmul(tf.transpose(X), error)\n",
    "  \n",
    "training_op = tf.assign(theta, theta - learning_rate* gradients)\n",
    "\n",
    "#Then define the batch size and compute the number of batches\n",
    "#batch_size = 100\n",
    "#n_batches  = np.ceil(n_test, batch_size)\n",
    "\n",
    "mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "file_witer  = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "        if(epoch %10 == 0):\n",
    "            summary_str = mse_summary.eval(feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "            file_witer.add_summary(summary_str)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
