{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mpl_toolkits\n",
    "#from mpl_toolkits.mpot3d import Axes3D\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as  tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model \n",
    "\n",
    "\n",
    "$y(x) = a + b_1 * X_1 + b_2*X_2 + b_3*X_3 + \\sigma \\epsilon$\n",
    "\n",
    "$\\epsilon \\approx N(0,1)$\n",
    "\n",
    "$b_1, b_2, b_3 = (0.5, 0.2, 0.1) $\n",
    "\n",
    "$\\sigma=0.1$\n",
    "\n",
    "\n",
    "$X_1, X_2, X_3$ uniformally distributed in [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate Data\n",
    "\n",
    "n_points = 5000\n",
    "n_features = 3\n",
    "\n",
    "bias = np.ones(n_points).reshape((-1,1))\n",
    "low  = -1 * np.ones((n_points, n_features),dtype='float')\n",
    "high  = np.ones((n_points, n_features),dtype='float')\n",
    "\n",
    "#similated Features\n",
    "X =  np.random.uniform(low=low, high=high)\n",
    "\n",
    "\n",
    "#simulated Noise\n",
    "noise = np.random.normal(size=(n_points,1))\n",
    "\n",
    "#outputr\n",
    "weights = np.array([1.0, 0.5, 0.2, 0.1])\n",
    "noise_std = 0.1\n",
    "\n",
    "Y = weights[0] * bias + np.dot(X, weights[1:] .reshape(-1,1)) + noise_std * noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.21116262,  0.64865642,  0.52176727],\n",
       "       [ 0.81182564, -0.51276811, -0.39792504],\n",
       "       [ 0.21076231,  0.41708824,  0.35746999],\n",
       "       ..., \n",
       "       [ 0.79189151,  0.09282696,  0.99337447],\n",
       "       [ 0.79393061, -0.45804693,  0.48559791],\n",
       "       [-0.65287268,  0.16716483, -0.5449959 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View X\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.14168298],\n",
       "       [ 1.11350971],\n",
       "       [ 1.09198463],\n",
       "       ..., \n",
       "       [ 1.59008521],\n",
       "       [ 1.43316489],\n",
       "       [ 0.64567421]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Y\n",
    "print(Y.shape)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data into train and test sets\n",
    "train_test_split = 4\n",
    "\n",
    "n_test = int(n_points/train_test_split)\n",
    "n_train = n_points - n_test\n",
    "\n",
    "X_train = X[:n_train, :]\n",
    "Y_train = Y[:n_train].reshape((-1,1))\n",
    "\n",
    "X_test = X[n_train:,:]\n",
    "Y_test = Y[n_train:].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1250, 3), (1250, 1), (3750, 3), (3750, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape, X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.placeholder(dtype, shape=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can do directly - but let us use Minibatch GRadient Descent\n",
    "#tf.placeholder(dtype, shape=None, name=None)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1) , name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_features + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = 2.0/n_train * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate* gradients)\n",
    "\n",
    "#Then define the batch size and compute the number of batches\n",
    "#batch_size = 100\n",
    "#n_batches  = np.ceil(n_test, batch_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99930358],\n",
       "       [ 0.47510859],\n",
       "       [ 0.17424433],\n",
       "       [ 0.11635426]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.001],\n",
       "       [ 0.025],\n",
       "       [ 0.026],\n",
       "       [-0.016]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diff from actual \n",
    "np.round(weights.reshape(-1,1) - best_theta,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualizing Using the tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "#'tf_logs/run-20180805063540/'\n",
    "\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1) , name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_features + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = 2.0/n_train * tf.matmul(tf.transpose(X), error)\n",
    "  \n",
    "training_op = tf.assign(theta, theta - learning_rate* gradients)\n",
    "\n",
    "#Then define the batch size and compute the number of batches\n",
    "#batch_size = 100\n",
    "#n_batches  = np.ceil(n_test, batch_size)\n",
    "\n",
    "mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "file_witer  = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "        if(epoch %10 == 0):\n",
    "            summary_str = mse_summary.eval(feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "            file_witer.add_summary(summary_str, epoch)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "file_witer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs2\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1) , name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_features + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "\n",
    "#============= Tidy ==================#\n",
    "# TensorBoard will give better grouped flow display\n",
    "#=====================================#\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse   = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "\n",
    "    \n",
    "gradients = 2.0/n_train * tf.matmul(tf.transpose(X), error)  \n",
    "training_op = tf.assign(theta, theta - learning_rate* gradients)\n",
    "\n",
    "mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "file_witer  = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "        if(epoch %10 == 0):\n",
    "            summary_str = mse_summary.eval(feed_dict={X: np.hstack([np.ones(X_train.shape[0]).reshape(-1,1),X_train]), \n",
    "                                         y: Y_train})\n",
    "            file_witer.add_summary(summary_str, epoch)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "file_witer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99930358],\n",
       "       [ 0.47510859],\n",
       "       [ 0.17424433],\n",
       "       [ 0.11635426]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta\n",
    "#Should be 1 and (0.5, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
