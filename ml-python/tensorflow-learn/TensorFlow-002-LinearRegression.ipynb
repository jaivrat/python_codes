{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mpl_toolkits\n",
    "#from mpl_toolkits.mpot3d import Axes3D\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as  tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model \n",
    "\n",
    "\n",
    "$y(x) = a + b_1 * X_1 + b_2*X_2 + b_3*X_3 + \\sigma \\epsilon$\n",
    "\n",
    "$\\epsilon \\approx N(0,1)$\n",
    "\n",
    "$b_1, b_2, b_3 = (0.5, 0.2, 0.1) $\n",
    "\n",
    "$\\sigma=0.1$\n",
    "\n",
    "\n",
    "$X_1, X_2, X_3$ uniformally distributed in [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Data\n",
    "\n",
    "n_points = 5000\n",
    "n_features = 3\n",
    "\n",
    "bias = np.ones(n_points).reshape((-1,1))\n",
    "low  = -1 * np.ones((n_points, n_features),dtype='float')\n",
    "high  = np.ones((n_points, n_features),dtype='float')\n",
    "\n",
    "#similated Features\n",
    "X =  np.random.uniform(low=low, high=high)\n",
    "\n",
    "\n",
    "#simulated Noise\n",
    "noise = np.random.normal(size=(n_points,1))\n",
    "\n",
    "#outputr\n",
    "weights = np.array([1.0, 0.5, 0.2, 0.1])\n",
    "noise_std = 0.1\n",
    "\n",
    "Y = weights[0] * bias + np.dot(X, weights[1:] .reshape(-1,1)) + noise_std * noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56657723],\n",
       "       [ 0.61752009],\n",
       "       [ 0.95641433],\n",
       "       ..., \n",
       "       [ 0.71649265],\n",
       "       [ 1.4849942 ],\n",
       "       [ 0.50911043]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data into train and test sets\n",
    "train_test_split = 4\n",
    "\n",
    "n_test = int(n_points/train_test_split)\n",
    "n_train = n_points - n_test\n",
    "\n",
    "X_train = X[:n_train, :]\n",
    "Y_train = Y[:n_train].reshape((-1,1))\n",
    "\n",
    "X_test = X[n_train:,:]\n",
    "Y_test = Y[n_train:].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1250, 3), (1250, 1), (3750, 3), (3750, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape, X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99903897]\n",
      " [ 0.50139548]\n",
      " [ 0.19649912]\n",
      " [ 0.10131431]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#add colum of ones\n",
    "X = np.hstack((np.ones(n_train).reshape((-1,1)), X_train))\n",
    "\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y_train)\n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99903897],\n",
       "       [ 0.50139548],\n",
       "       [ 0.19649912],\n",
       "       [ 0.10131431]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, Y_train)\n",
    "\n",
    "np.r_[lin_reg.intercept_.reshape(-1,1), lin_reg.coef_.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99903917],\n",
       "       [ 0.50139558],\n",
       "       [ 0.19649917],\n",
       "       [ 0.10131431]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np = np.hstack((np.ones(n_train).reshape((-1,1)), X_train))\n",
    "\n",
    "X = tf.constant(X_np, dtype=tf.float32, name = \"X\")\n",
    "y = tf.constant(Y_train, dtype=tf.float32, name = \"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple class for Linear Regression\n",
    "\n",
    "Implement the Normal Equation and MLE solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, n_features, learning_rate=0.05, L=0):\n",
    "        \n",
    "        #input placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, n_features], name=\"X\")\n",
    "        self.Y = tf.placeholder(tf.float32, [None, 1], name = \"Y\")\n",
    "        \n",
    "        #regression paramaters for analytical Solution using Normal Equan\n",
    "        self.theta_in = tf.placeholder(tf.float32, [n_features+1,None])\n",
    "        \n",
    "        #Augmented data matrix is obtained by adding a column of ones to\n",
    "        #the data matrix\n",
    "        data_plus_bias = tf.concat([tf.ones([tf.shape(self.X,)[0],1]), self.X], axis=1)\n",
    "        \n",
    "        XT = tf.transpose(data_plus_bias)\n",
    "        \n",
    "        ###########################################\n",
    "        # The normal equation for Linear Regression\n",
    "        ###########################################\n",
    "        self.theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,data_plus_bias)),XT),self.Y)\n",
    "        \n",
    "        \n",
    "        #mean square error in terms of theta = theta_in\n",
    "        self.lr_mse = tf.reduce_mean(tf.square(tf.matmul(data_plus_bias, self.theta_in)) - self.Y)\n",
    "        \n",
    "        ##############################################\n",
    "        #Estimate Model using MLE\n",
    "        \n",
    "        #Regression paramaters for the maximum likelihood method\n",
    "        # Note that there are n_features+2 parameters, as one is added for the intercept\n",
    "        # and another one for the std dev for the noise\n",
    "        self.weights = tf.Variable(tf.random_normal([n_features+2, 1]))\n",
    "        \n",
    "        #prediction from the model\n",
    "        self.output = tf.matmul(data_plus_bias, self.weights[:-1,:])\n",
    "        \n",
    "        gauss = tf.distributions.Normal(loc=0.0, scale = 1.0)\n",
    "        \n",
    "        #STadard Deviation of the Gaussian noise is modelled as a square of the last\n",
    "        #model weight\n",
    "        sigma = 0.0001 + tf.square(self.weights[-1])\n",
    "        \n",
    "        log_LL = tf.log(0.00001 + (1/sigma) * gauss.prob((self.Y - self.output)/sigma))\n",
    "        \n",
    "        #Loss is the negative log-likelihood\n",
    "        self.loss = -tf.reduce_mean(log_LL)\n",
    "        \n",
    "        #TF node defining an Op for on training set\n",
    "        self.train_step = (tf.train.AdamOptimizer(learning_rate).minimize(self.loss), self.loss)\n",
    "        \n",
    "    def generate_data(n_points = 10000,\n",
    "                     n_features = 3,\n",
    "                     weights = np.array([1.0, 0.5, 0.2, 0.1]),\n",
    "                     noise_std = 0.1):\n",
    "        \n",
    "        bias = np.ones(n_points).reshape((-1,1))        \n",
    "        low  = -1 * np.ones((n_points, n_features),dtype='float')\n",
    "        high  = np.ones((n_points, n_features),dtype='float')\n",
    "        \n",
    "        #simulated Features\n",
    "        X =  np.random.uniform(low=low, high=high)\n",
    "        \n",
    "        #simulated Noise\n",
    "        noise = np.random.normal(size=(n_points,1))\n",
    "        \n",
    "        #output\n",
    "        weights = np.array([1.0, 0.5, 0.2, 0.1])\n",
    "        noise_std = 0.1\n",
    "        \n",
    "        Y = weights[0] * bias + np.dot(X, weights[1:] .reshape(-1,1)) + noise_std * noise\n",
    "        \n",
    "        return(X,Y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    n_points = 5000\n",
    "    n_features = 3\n",
    "    \n",
    "    #n_features + 1 weights (one for constant feature)\n",
    "    weights = np.array([1.0, 0.5, 0.2, 0.1])\n",
    "    noise_std = 0.1\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    #Make data\n",
    "    (X,Y) = Model.generate_data(n_points = n_points,\n",
    "                                 n_features = n_features,\n",
    "                                 weights = weights,\n",
    "                                 noise_std = noise_std)\n",
    "    \n",
    "    #split the data into train and test sets\n",
    "    train_test_split = 4 #1/4 to be used for test\n",
    "    \n",
    "    n_test = int(n_points/train_test_split)\n",
    "    n_train = n_points - n_test\n",
    "    \n",
    "    X_train = X[:n_train, :]\n",
    "    Y_train = Y[:n_train].reshape((-1,1))\n",
    "    \n",
    "    X_test = X[n_train:,:]\n",
    "    Y_test = Y[n_train:].reshape((-1,1))\n",
    "    \n",
    "    #create an instance of the Linear Regression model class\n",
    "    model = Model(n_features=n_features, learning_rate=learning_rate)\n",
    "    \n",
    "    #train the model\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #Normal Equations for Linear Regression\n",
    "        theta_value = sess.run(model.theta, feed_dict={\n",
    "            model.X: X_train,\n",
    "            model.Y: Y_train\n",
    "        })\n",
    "        \n",
    "        lr_mse_train = sess.run(model.lr_mse, feed_dict={\n",
    "            model.X: X_train,\n",
    "            model.Y: Y_train,\n",
    "            model.theta_in: theta_value\n",
    "        })\n",
    "        \n",
    "        lr_mse_test = sess.run(model.lr_mse, feed_dict={\n",
    "            model.X: X_test,\n",
    "            model.Y: Y_test,\n",
    "            model.theta_in: theta_value\n",
    "        })\n",
    "        \n",
    "        print(\"====== Linear Regression with the Normal Equation =======\")\n",
    "        print(theta_value)\n",
    "        print(\"Linear regression train error:\", lr_mse_train)\n",
    "        print(\"Linear regression test error :\", lr_mse_test)\n",
    "        \n",
    "        #Now train the MLE parameters\n",
    "        for i in range(0,1000):\n",
    "            (_,loss), weights = sess.run((model.train_step, model.weights), \n",
    "                                         feed_dict={\n",
    "                                                    model.X: X_train,\n",
    "                                                    model.Y: Y_train\n",
    "                                                })\n",
    "            \n",
    "        #make test predictions\n",
    "        Y_test_predicted = sess.run(model.output, feed_dict = {\n",
    "                                                        model.X: X_test\n",
    "                                                    })\n",
    "        \n",
    "        #output std sigma is a square of the last weight\n",
    "        std_model = weights[-1]**2\n",
    "        print(\"===== Linear Regression with MLE =========\")\n",
    "        print(\"Negative Log-Likelihood\", loss)\n",
    "        print(\"MLE fitted parameters: \")\n",
    "        print(weights[0:-1])\n",
    "        print(\"Fitted std of noise: \", std_model)\n",
    "        \n",
    "        fig.plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(X_test[:,1], X_test[:,2], Y_test, s=1, c=\"#000000\")\n",
    "        ax.scatter(X_test[:,1], X_test[:,2], Y_test_predicted, s=1, c=\"#FF0000\")\n",
    "        plt.show()\n",
    "        \n",
    "        sess.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Linear Regression with the Normal Equation =======\n",
      "[[ 1.00163627]\n",
      " [ 0.50377536]\n",
      " [ 0.19868284]\n",
      " [ 0.10164218]]\n",
      "Linear regression train error: 0.114171\n",
      "Linear regression test error : 0.0992593\n",
      "===== Linear Regression with MLE =========\n",
      "Negative Log-Likelihood -0.891624\n",
      "MLE fitted parameters: \n",
      "[[ 1.00163853]\n",
      " [ 0.50377142]\n",
      " [ 0.1986825 ]\n",
      " [ 0.10163619]]\n",
      "Fitted std of noise:  [ 0.09910183]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4591af7673e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-5cd5e7b53840>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitted std of noise: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#000000\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fig' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
