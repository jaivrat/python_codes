{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial 15 - Transfer Learning\n",
    "Taken from \n",
    "\n",
    "* https://www.youtube.com/watch?v=K0lWSB2QoIQ\n",
    "\n",
    "* https://github.com/python-engineer/pytorchTutorial/blob/master/15_transfer_learning.py\n",
    "\n",
    "Model developed for one task can be resused for a model in second task. e.g we can use model to classify birds and cats and then use to to classify, just with modifications in **last layer** to classify bees and dogs.\n",
    "\n",
    "This helps to quickly generate new models. To train completely new model would have been very time consuming (can take days or weeks to do so)\n",
    "\n",
    "So this approach just focuses on training the last layer and we do not need to train whole model again.\n",
    "\n",
    "Have a look at CNN archicecture - we just train the last fully connected layers and create a new model from old model:\n",
    "\n",
    "<img src=\"images/transfer-learning.png\" width=900>\n",
    "\n",
    "\n",
    "Here we will be using pre-trained **Res-Net-18 cnn** which is pre-trained with more than million images from imagenet database. This network is **18 layers** deep and can classify objects into **1000 object categories.**\n",
    "\n",
    "But in our example we have only two class classification - bees and ants. Lets try.\n",
    "\n",
    "\n",
    "We will also try to use \n",
    "\n",
    "* Imagefolder\n",
    "\n",
    "* Sceduler (to change the learning rate)\n",
    "\n",
    "* Transfer Learning\n",
    "\n",
    "\n",
    "We have save data from https://download.pytorch.org/tutorial/hymenoptera_data.zip into *./data* folder and structure looks like this\n",
    "\n",
    "<img src=\"images/folder_structure.png\" width=600>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "# some transforms needed\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# import data\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders    = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                 batch_size = 4,\n",
    "                                                 shuffle = True, \n",
    "                                                 num_workers = 0) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 244\n",
       "     Root location: data/hymenoptera_data/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.5 0.5 0.5], std=[0.25 0.25 0.25])\n",
       "            ),\n",
       " 'val': Dataset ImageFolder\n",
       "     Number of datapoints: 153\n",
       "     Root location: data/hymenoptera_data/val\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
       "                CenterCrop(size=(224, 224))\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.5 0.5 0.5], std=[0.25 0.25 0.25])\n",
       "            )}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fea08883d90>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7fea08883d50>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 244, 'val': 153}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-'*10)\n",
    "        \n",
    "        # Each epoch has a training and a validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # set model to training mode\n",
    "            else:\n",
    "                model.eval() # set model to evaluation mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)  #??? why * inputs.size(0) \n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()     # ????\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "            \n",
    "    # outside the loop now     \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use transfer learning now]\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer. Pretraining of the loaded model is on Imagenet data (https://www.image-net.org/ , https://www.image-net.org/download.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features in input features of last layer: 512\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "# Pretraining of the loaded model is on Imagenet data\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Exchange last fc layer \n",
    "#1. Get number of input features from last layer\n",
    "num_ftrs = model.fc.in_features\n",
    "print(f'Num features in input features of last layer: {num_ftrs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/jvsingh/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a94e3b40c94afa843af568b4622c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.6557\n",
      "val Loss: 0.4501 Acc: 0.7974\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.4771 Acc: 0.7828\n",
      "val Loss: 0.3480 Acc: 0.8824\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4582 Acc: 0.8197\n",
      "val Loss: 0.2824 Acc: 0.9281\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4025 Acc: 0.8484\n",
      "val Loss: 0.2541 Acc: 0.9216\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4055 Acc: 0.7951\n",
      "val Loss: 0.2194 Acc: 0.9412\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3646 Acc: 0.8730\n",
      "val Loss: 0.2252 Acc: 0.9542\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.4495 Acc: 0.7664\n",
      "val Loss: 0.2076 Acc: 0.9346\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3374 Acc: 0.8525\n",
      "val Loss: 0.2048 Acc: 0.9346\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3727 Acc: 0.8402\n",
      "val Loss: 0.2130 Acc: 0.9412\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3565 Acc: 0.8566\n",
      "val Loss: 0.2046 Acc: 0.9542\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3251 Acc: 0.8689\n",
      "val Loss: 0.2008 Acc: 0.9477\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3640 Acc: 0.8566\n",
      "val Loss: 0.2228 Acc: 0.9412\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3300 Acc: 0.8648\n",
      "val Loss: 0.2049 Acc: 0.9412\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.4278 Acc: 0.7787\n",
      "val Loss: 0.2062 Acc: 0.9346\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3446 Acc: 0.8525\n",
      "val Loss: 0.1986 Acc: 0.9542\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3540 Acc: 0.8484\n",
      "val Loss: 0.2009 Acc: 0.9346\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3538 Acc: 0.8279\n",
      "val Loss: 0.1975 Acc: 0.9477\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.3569 Acc: 0.8770\n",
      "val Loss: 0.2152 Acc: 0.9346\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3149 Acc: 0.8443\n",
      "val Loss: 0.2000 Acc: 0.9477\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.4181 Acc: 0.8074\n",
      "val Loss: 0.1941 Acc: 0.9477\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3568 Acc: 0.8361\n",
      "val Loss: 0.2045 Acc: 0.9412\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3286 Acc: 0.8525\n",
      "val Loss: 0.2033 Acc: 0.9412\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3793 Acc: 0.8115\n",
      "val Loss: 0.2048 Acc: 0.9412\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.3430 Acc: 0.8566\n",
      "val Loss: 0.2067 Acc: 0.9412\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3663 Acc: 0.8402\n",
      "val Loss: 0.2044 Acc: 0.9412\n",
      "\n",
      "Training complete in 19m 26s\n",
      "Best val Acc: 0.954248\n"
     ]
    }
   ],
   "source": [
    "# We are creating a new layer and assign it to last layer\n",
    "# Here the size of each output sample is set to 2 (because 2 classes ants and nbes now)\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# now we have new model - we define our loss criteria\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# sceduler : This will update the learning rate\n",
    "# - the below prameters mean that at every 7 epochs, our learning rate \n",
    "# - will be multiplied by gamma(=0.1)\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "#for epoch in range(100):\n",
    "#    train()  # optimizer.step()\n",
    "#    evaluate()\n",
    "#    scheduler.step()\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get very good results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6864 Acc: 0.5410\n",
      "val Loss: 0.5791 Acc: 0.7255\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6136 Acc: 0.6598\n",
      "val Loss: 0.4548 Acc: 0.8431\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5377 Acc: 0.7459\n",
      "val Loss: 0.3790 Acc: 0.8497\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5046 Acc: 0.7664\n",
      "val Loss: 0.3407 Acc: 0.8889\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4657 Acc: 0.7951\n",
      "val Loss: 0.3042 Acc: 0.9085\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4397 Acc: 0.8115\n",
      "val Loss: 0.2925 Acc: 0.9020\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.4576 Acc: 0.7787\n",
      "val Loss: 0.2801 Acc: 0.9085\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.4404 Acc: 0.7992\n",
      "val Loss: 0.2804 Acc: 0.8954\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.4139 Acc: 0.8484\n",
      "val Loss: 0.2697 Acc: 0.9085\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.4268 Acc: 0.8156\n",
      "val Loss: 0.2810 Acc: 0.9020\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3749 Acc: 0.8607\n",
      "val Loss: 0.2637 Acc: 0.9085\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3874 Acc: 0.8566\n",
      "val Loss: 0.2584 Acc: 0.9281\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.4384 Acc: 0.8115\n",
      "val Loss: 0.2668 Acc: 0.9020\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3972 Acc: 0.8402\n",
      "val Loss: 0.2671 Acc: 0.9020\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3663 Acc: 0.8893\n",
      "val Loss: 0.2727 Acc: 0.9020\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.4436 Acc: 0.8033\n",
      "val Loss: 0.2617 Acc: 0.9085\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.4356 Acc: 0.7828\n",
      "val Loss: 0.2592 Acc: 0.9150\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.4038 Acc: 0.8197\n",
      "val Loss: 0.2670 Acc: 0.9020\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3934 Acc: 0.8361\n",
      "val Loss: 0.2599 Acc: 0.9346\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.4002 Acc: 0.8525\n",
      "val Loss: 0.2979 Acc: 0.8889\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.4528 Acc: 0.7787\n",
      "val Loss: 0.2868 Acc: 0.9020\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.4138 Acc: 0.8279\n",
      "val Loss: 0.2622 Acc: 0.9216\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3705 Acc: 0.8238\n",
      "val Loss: 0.2787 Acc: 0.9085\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.4054 Acc: 0.8238\n",
      "val Loss: 0.2706 Acc: 0.8954\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3810 Acc: 0.8402\n",
      "val Loss: 0.2555 Acc: 0.9216\n",
      "\n",
      "Training complete in 9m 13s\n",
      "Best val Acc: 0.934641\n"
     ]
    }
   ],
   "source": [
    "#### ConvNet as fixed feature extractor ####\n",
    "# Here, we need to freeze all the network except the final layer.\n",
    "# We need to set requires_grad == False to freeze the parameters so that \n",
    "# the gradients are not computed in backward()\n",
    "model_conv = models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model_conv.parameters(), lr=0.001)\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model_conv, criterion, optimizer, step_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this takes lesser time only 9m as compared to training full which took 19m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
