{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial 13 - Feed-Forward Neural Network\n",
    "\n",
    "https://www.youtube.com/watch?v=oPhxf2fXHkQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# DataLoader, Transformation\n",
    "# Multilayer Neural Net, activation function\n",
    "# Loss and Optimizer\n",
    "# Training Loop (batch training)\n",
    "# Model Evaluation\n",
    "# GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cpu\n"
     ]
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device:{device}\")\n",
    "# hyper parameters\n",
    "input_size = 784 # 28 x 28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root = \"./data\", \n",
    "                                           train = True,\n",
    "                                           transform = transforms.ToTensor(),\n",
    "                                           download = True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = \"./data\", \n",
    "                                          train = False,\n",
    "                                          transform = transforms.ToTensor(),\n",
    "                                          download= True)\n",
    "\n",
    "# we shuffle\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                           batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "\n",
    "# we dont shuffle\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "                                           batch_size = batch_size,\n",
    "                                          shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Let us look as one batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "\n",
    "print(samples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
    "\n",
    "1. Since we put batch size of 100, so one fetch using .next gets us 100 samples\n",
    "\n",
    "2. Next is colour channels, which is 1 in this case - we do not have anu colour channel\n",
    "\n",
    "3. 28x28 is actual image array\n",
    "\n",
    "4. torch.Size([100]): for each data bach we have 100 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    # 2 rows and three columns\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    # i th sample \n",
    "    # 0: because we want to access first channel(we have only one)\n",
    "    # cmap: colour map\n",
    "    plt.imshow(samples[i][0], cmap=\"gray\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see digits above. To train we need to make a fully connected neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 100/600 loss=0.3614\n",
      "epoch 1/5, step 200/600 loss=0.4087\n",
      "epoch 1/5, step 300/600 loss=0.2504\n",
      "epoch 1/5, step 400/600 loss=0.2764\n",
      "epoch 1/5, step 500/600 loss=0.1843\n",
      "epoch 1/5, step 600/600 loss=0.1372\n",
      "epoch 2/5, step 100/600 loss=0.3653\n",
      "epoch 2/5, step 200/600 loss=0.4223\n",
      "epoch 2/5, step 300/600 loss=0.0971\n",
      "epoch 2/5, step 400/600 loss=0.1543\n",
      "epoch 2/5, step 500/600 loss=0.1381\n",
      "epoch 2/5, step 600/600 loss=0.2235\n",
      "epoch 3/5, step 100/600 loss=0.1300\n",
      "epoch 3/5, step 200/600 loss=0.0679\n",
      "epoch 3/5, step 300/600 loss=0.1251\n",
      "epoch 3/5, step 400/600 loss=0.1017\n",
      "epoch 3/5, step 500/600 loss=0.0652\n",
      "epoch 3/5, step 600/600 loss=0.1160\n",
      "epoch 4/5, step 100/600 loss=0.0933\n",
      "epoch 4/5, step 200/600 loss=0.1037\n",
      "epoch 4/5, step 300/600 loss=0.1195\n",
      "epoch 4/5, step 400/600 loss=0.0798\n",
      "epoch 4/5, step 500/600 loss=0.1344\n",
      "epoch 4/5, step 600/600 loss=0.0586\n",
      "epoch 5/5, step 100/600 loss=0.1159\n",
      "epoch 5/5, step 200/600 loss=0.0647\n",
      "epoch 5/5, step 300/600 loss=0.0943\n",
      "epoch 5/5, step 400/600 loss=0.0188\n",
      "epoch 5/5, step 500/600 loss=0.0639\n",
      "epoch 5/5, step 600/600 loss=0.1027\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  #applies softmax\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "#trainign loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # we have to reshape the image : 100, 1 , 28, 28\n",
    "        # we need 100, 784   (784 = 28 x 28)\n",
    "        images = images.reshape(-1, 28 * 28).to(device) #pushes to gpu if avilable\n",
    "        lables = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backwards \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Tutorial says zero_grad can be put in any order\n",
    "        #but only thing to make sure is that it must be \n",
    "        #called before next iteration\n",
    "        # I wonder why ? because I am thinking that optimizer.step() may be using \n",
    "        # gradient information to step.\n",
    "        # it seems that optimizer.step() might be using gradient info inside to step. So if you make it zero before stepping, then first step goes waste. However the code still works because the next step() call may be using gradient of previous iteration. So, there might be a \"loss\" of one batch of data, but still it works.\n",
    "        \n",
    "        \n",
    "        if (i + 1)% 100 == 0:\n",
    "            print(f'epoch {epoch + 1}/{num_epochs}, step {i+1}/{n_total_steps} loss={loss.item():.4f}')\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are done with training above - now lets do  testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 97.17\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28 * 28).to(device) #pushes to gpu if avilable\n",
    "        lables = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1) #along dimension 1\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct/n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
