{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tutorial - RNN & LSTM & GRU - Recurrent Neural Nets\n",
    "https://www.youtube.com/watch?v=0_PgWWmauHk\n",
    "\n",
    "(From python engineer's youtube lectures)\n",
    "\n",
    "Erlier tutorial was on RNN - \n",
    "<img src=\"images/rnn-unfolded.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous tut, we developed owr own RNN from scratch. Here we use pytorch's RNN module.\n",
    "\n",
    "We can easily switch then from RNN to LSTM and GRU easily.\n",
    "\n",
    "We start with out tutprial 13 code - which is image classification using NN. However we will use RNN to do image classification. **Generally we never use RNN to do image classification - but here just to demonstate the usage we do so, treating input as sequence and setting up correct shapes.**\n",
    "\n",
    "\n",
    "We will see  we can achive accuracy using RNNs.\n",
    "<img src=\"images/rnn-applications.png\">\n",
    "\n",
    "Here we will use many to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Earlier we used 28x28 = 784 as image size input. We flattened the image as 784 size vectors.\n",
    "But here we treat image as a sequence of vectors of dimesion 28 each (is one row at a time) - so we set input_size=28 and sequence length = 28\n",
    "\n",
    "We make hidden_size = 128, ( we can chose any other size)\n",
    "\n",
    "\n",
    "num_layers = 2 => This means we are stacking 2 RNNS togethere - so that second RNN is taking input of first RNN's output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cpu\n"
     ]
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device:{device}\")\n",
    "\n",
    "# hyper parameters\n",
    "# 28 x 28 : image size - we treat \n",
    "#input_size = 784 \n",
    "#hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root = \"./data\", \n",
    "                                           train = True,\n",
    "                                           transform = transforms.ToTensor(),\n",
    "                                           download = True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = \"./data\", \n",
    "                                          train = False,\n",
    "                                          transform = transforms.ToTensor(),\n",
    "                                          download= True)\n",
    "\n",
    "# we shuffle\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                           batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "\n",
    "# we dont shuffle\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "                                           batch_size = batch_size,\n",
    "                                          shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYMODEL(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, model_type):\n",
    "        #super(RNN, self).__init__()\n",
    "        super(MYMODEL, self).__init__()\n",
    "        \n",
    "        # just to call rnn or gru - in one place\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # we create builtin RNN model\n",
    "        # batch_first = True : means batch will be the first dimension - we will need to \n",
    "        # match the input accordingly ie # input  shape will be x -> (batch_size , sequence_length, input_size)\n",
    "        if model_type == \"rnn\":\n",
    "            self.mod = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        elif model_type == \"gru\":\n",
    "            self.mod = nn.GRU(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        elif model_type == \"lstm\":\n",
    "            self.mod = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
    "\n",
    "        # (we use last time step to do the classification, so the Linear layer is hidden_size x num_classes)\n",
    "        # (we need last hidden size as linear layer)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(f\"x.size():{x.size()}\")\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # call out RNN\n",
    "        if self.model_type in [\"rnn\", \"gru\"]:\n",
    "            out, _ = self.mod(x, h0)\n",
    "        elif self.model_type == \"lstm\":\n",
    "            # if LSTM, it needs an intial cell state\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "            out, _ = self.mod(x, (h0, c0))\n",
    "            \n",
    "        # out is of zise : batch_size, seq_length, hidden_sizw: (N , 28, 128)\n",
    "        # we only last timestep\n",
    "        out = out[:,-1, :] \n",
    "        # now out os (N,128)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 100/600 loss=1.0599\n",
      "epoch 1/5, step 200/600 loss=0.4493\n",
      "epoch 1/5, step 300/600 loss=0.2735\n",
      "epoch 1/5, step 400/600 loss=0.1501\n",
      "epoch 1/5, step 500/600 loss=0.1524\n",
      "epoch 1/5, step 600/600 loss=0.1294\n",
      "epoch 2/5, step 100/600 loss=0.1233\n",
      "epoch 2/5, step 200/600 loss=0.0719\n",
      "epoch 2/5, step 300/600 loss=0.1413\n",
      "epoch 2/5, step 400/600 loss=0.1121\n",
      "epoch 2/5, step 500/600 loss=0.0468\n",
      "epoch 2/5, step 600/600 loss=0.1027\n",
      "epoch 3/5, step 100/600 loss=0.0365\n",
      "epoch 3/5, step 200/600 loss=0.1134\n",
      "epoch 3/5, step 300/600 loss=0.0917\n",
      "epoch 3/5, step 400/600 loss=0.0475\n",
      "epoch 3/5, step 500/600 loss=0.0713\n",
      "epoch 3/5, step 600/600 loss=0.1000\n",
      "epoch 4/5, step 100/600 loss=0.0503\n",
      "epoch 4/5, step 200/600 loss=0.0952\n",
      "epoch 4/5, step 300/600 loss=0.1121\n",
      "epoch 4/5, step 400/600 loss=0.0179\n",
      "epoch 4/5, step 500/600 loss=0.0315\n",
      "epoch 4/5, step 600/600 loss=0.0311\n",
      "epoch 5/5, step 100/600 loss=0.0288\n",
      "epoch 5/5, step 200/600 loss=0.0132\n",
      "epoch 5/5, step 300/600 loss=0.0158\n",
      "epoch 5/5, step 400/600 loss=0.0476\n",
      "epoch 5/5, step 500/600 loss=0.0282\n",
      "epoch 5/5, step 600/600 loss=0.0272\n"
     ]
    }
   ],
   "source": [
    "#model = MYMODEL(input_size, hidden_size, num_layers, num_classes, \"rnn\")\n",
    "#model = MYMODEL(input_size, hidden_size, num_layers, num_classes, \"gru\")\n",
    "model = MYMODEL(input_size, hidden_size, num_layers, num_classes, \"lstm\")\n",
    "\n",
    "\n",
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  #applies softmax\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "#trainign loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # original shape : 100, 1 , 28, 28\n",
    "        # we need [100,  28 , 28] \n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device) #pushes to gpu if avilable\n",
    "        lables = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backwards \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Tutorial says zero_grad can be put in any order\n",
    "        #but only thing to make sure is that it must be \n",
    "        #called before next iteration\n",
    "        # I wonder why ? because I am thinking that optimizer.step() may be using \n",
    "        # gradient information to step.\n",
    "        # it seems that optimizer.step() might be using gradient info inside to step. So if you make it zero before stepping, then first step goes waste. However the code still works because the next step() call may be using gradient of previous iteration. So, there might be a \"loss\" of one batch of data, but still it works.\n",
    "        \n",
    "        \n",
    "        if (i + 1)% 100 == 0:\n",
    "            print(f'epoch {epoch + 1}/{num_epochs}, step {i+1}/{n_total_steps} loss={loss.item():.4f}')\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 98.56\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device) #pushes to gpu if avilable\n",
    "        lables = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1) #along dimension 1\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct/n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get an accuracy:\n",
    "\n",
    "* rnn = 96%\n",
    "\n",
    "* gru = 98%\n",
    "\n",
    "* lstm = 98.56%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
