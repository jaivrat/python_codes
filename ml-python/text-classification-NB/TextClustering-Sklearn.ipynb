{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We try text clustering, with news groups data. \n",
    "\n",
    "The tutorial has been taken from http://scikit-learn.org/stable/auto_examples/text/document_clustering.html#sphx-glr-auto-examples-text-document-clustering-py\n",
    "\n",
    "Author of the turorial\n",
    "###### Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "######         Lars Buitinck\n",
    "###### License: BSD 3 clause\n",
    "\n",
    "\n",
    "### Load some categories data from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "# categories = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "3387 documents\n",
      "4 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             shuffle=True, random_state=42)\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 1, 1, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset.target\n",
    "labels[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.unique(labels))\n",
    "true_k = np.unique(labels).shape[0]\n",
    "true_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "done in 0.633680s\n",
      "n_samples: 3387, n_features: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
    "\n",
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "use_idf = True\n",
    "n_features = 10\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=n_features,\n",
    "                                 min_df=2, stop_words='english',\n",
    "                                 use_idf=use_idf)\n",
    "\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
      "    n_clusters=4, n_init=1, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=True)\n",
      "Initialization complete\n",
      "Iteration  0, inertia 2405.973\n",
      "Iteration  1, inertia 1857.665\n",
      "Iteration  2, inertia 1821.776\n",
      "Iteration  3, inertia 1757.259\n",
      "Iteration  4, inertia 1701.503\n",
      "Iteration  5, inertia 1683.263\n",
      "Iteration  6, inertia 1677.052\n",
      "Iteration  7, inertia 1675.694\n",
      "Iteration  8, inertia 1675.098\n",
      "Iteration  9, inertia 1674.673\n",
      "Iteration 10, inertia 1674.584\n",
      "Iteration 11, inertia 1674.180\n",
      "Iteration 12, inertia 1673.973\n",
      "Iteration 13, inertia 1673.932\n",
      "Iteration 14, inertia 1673.893\n",
      "Iteration 15, inertia 1673.861\n",
      "Iteration 16, inertia 1673.702\n",
      "Iteration 17, inertia 1673.675\n",
      "Iteration 18, inertia 1673.634\n",
      "Converged at iteration 18: center shift 4.060555e-06 within tolerance 6.970741e-06\n",
      "done in 0.121s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Do LSA ?\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "verbose = True\n",
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,  verbose=verbose)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.025\n",
      "Completeness: 0.026\n",
      "V-measure: 0.026\n",
      "Adjusted Rand-Index: 0.024\n",
      "Silhouette Coefficient: 0.191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
