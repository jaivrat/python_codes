{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "#helpper function\n",
    "import numpy as np\n",
    "\n",
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data in\n",
    "df = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'admit', u'gre', u'gpa', u'prestige'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rename the 'rank' column because there is also a DataFrame method called 'rank'\n",
    "df.columns = [\"admit\", \"gre\", \"gpa\", \"prestige\"]\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics & Looking at the data\n",
    "Now that we've got everything loaded into Python and named appropriately let's take a look at the data. We can use the pandas function describe to give us a summarized view of everything--describe is analogous to summary in R. There's also function for calculating the standard deviation, std. I've included it here to be consistent UCLA's tutorial, but the standard deviation is also included in describe.\n",
    "\n",
    "A feature I really like in pandas is the pivot_table/crosstab aggregations. crosstab makes it really easy to do multidimensional frequency tables (sort of like table in R). You might want to play around with this to look at different cuts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            admit         gre         gpa   prestige\n",
      "count  400.000000  400.000000  400.000000  400.00000\n",
      "mean     0.317500  587.700000    3.389900    2.48500\n",
      "std      0.466087  115.516536    0.380567    0.94446\n",
      "min      0.000000  220.000000    2.260000    1.00000\n",
      "25%      0.000000  520.000000    3.130000    2.00000\n",
      "50%      0.000000  580.000000    3.395000    2.00000\n",
      "75%      1.000000  660.000000    3.670000    3.00000\n",
      "max      1.000000  800.000000    4.000000    4.00000\n"
     ]
    }
   ],
   "source": [
    "# summarize the data\n",
    "print df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit         0.466087\n",
      "gre         115.516536\n",
      "gpa           0.380567\n",
      "prestige      0.944460\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# take a look at the standard deviation of each column\n",
    "print df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestige   1   2   3   4\n",
      "admit                   \n",
      "0         28  97  93  55\n",
      "1         33  54  28  12\n"
     ]
    }
   ],
   "source": [
    "# frequency table cutting presitge and whether or not someone was admitted\n",
    "print pd.crosstab(df['admit'], df['prestige'], rownames=['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c843f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot all of the columns\n",
    "df.hist()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy variables\n",
    "pandas gives you a great deal of control over how categorical variables are represented. We're going dummify the \"prestige\" column using get_dummies.\n",
    "\n",
    "get_dummies creates a new DataFrame with binary indicator variables for each category/option in the column specified. In this case, prestige has four levels: 1, 2, 3 and 4 (1 being most prestigious). When we call get_dummies, we get a dataframe with four columns, each of which describes one of those levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prestige_1  prestige_2  prestige_3  prestige_4\n",
      "0           0           0           1           0\n",
      "1           0           0           1           0\n",
      "2           1           0           0           0\n",
      "3           0           0           0           1\n",
      "4           0           0           0           1\n"
     ]
    }
   ],
   "source": [
    "# dummify rank\n",
    "dummy_ranks = pd.get_dummies(df['prestige'], prefix='prestige')\n",
    "print dummy_ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  prestige_2  prestige_3  prestige_4\n",
      "0      0  380  3.61           0           1           0\n",
      "1      1  660  3.67           0           1           0\n",
      "2      1  800  4.00           0           0           0\n",
      "3      1  640  3.19           0           0           1\n",
      "4      0  520  2.93           0           0           1\n"
     ]
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that's done, we merge the new dummy columns into the original dataset and get rid of the prestige column which we no longer need.\n",
    "\n",
    "Lastly we're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  prestige_2  prestige_3  prestige_4  intercept\n",
      "0      0  380  3.61           0           1           0        1.0\n",
      "1      1  660  3.67           0           1           0        1.0\n",
      "2      1  800  4.00           0           0           0        1.0\n",
      "3      1  640  3.19           0           0           1        1.0\n",
      "4      0  520  2.93           0           0           1        1.0\n"
     ]
    }
   ],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the regression\n",
    "Actually doing the Logistic Regression is quite simple. Specify the column containing the variable you're trying to predict followed by the columns that the model should use to make the prediction.\n",
    "\n",
    "In our case we'll be predicting the admit column using gre, gpa, and the prestige dummy variables prestige_2, prestige_3 and prestige_4. We're going to treat prestige_1 as our baseline and exclude it from our fit. This is done to prevent multicollinearity, or the dummy variable trap caused by including a dummy variable for every single category.\n",
    "\n",
    "\n",
    "Since we're doing a logistic regression, we're going to use the statsmodels Logit function. For details on other models available in statsmodels, check out their docs [here](http://www.statsmodels.org/stable/index.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "train_cols = data.columns[1:]\n",
    "# Index([gre, gpa, prestige_2, prestige_3, prestige_4], dtype=object)\n",
    "\n",
    "logit = sm.Logit(data['admit'], data[train_cols])\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the results\n",
    "One of my favorite parts about statsmodels is the summary output it gives. If you're coming from R, I think you'll like the output and find it very familiar too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  400\n",
      "Model:                          Logit   Df Residuals:                      394\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sun, 02 Jul 2017   Pseudo R-squ.:                 0.08292\n",
      "Time:                        15:40:47   Log-Likelihood:                -229.26\n",
      "converged:                       True   LL-Null:                       -249.99\n",
      "                                        LLR p-value:                 7.578e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "gre            0.0023      0.001      2.070      0.038         0.000     0.004\n",
      "gpa            0.8040      0.332      2.423      0.015         0.154     1.454\n",
      "prestige_2    -0.6754      0.316     -2.134      0.033        -1.296    -0.055\n",
      "prestige_3    -1.3402      0.345     -3.881      0.000        -2.017    -0.663\n",
      "prestige_4    -1.5515      0.418     -3.713      0.000        -2.370    -0.733\n",
      "intercept     -3.9900      1.140     -3.500      0.000        -6.224    -1.756\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# cool enough to deserve it's own gist\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get a great overview of the coefficients of the model, how well those coefficients fit, the overall fit quality, and several other statistical measures.\n",
    "\n",
    "The result object also lets you to isolate and inspect parts of the model output. The confidence interval gives you an idea for how robust the coefficients of the model are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1\n",
      "gre         0.000120  0.004409\n",
      "gpa         0.153684  1.454391\n",
      "prestige_2 -1.295751 -0.055135\n",
      "prestige_3 -2.016992 -0.663416\n",
      "prestige_4 -2.370399 -0.732529\n",
      "intercept  -6.224242 -1.755716\n"
     ]
    }
   ],
   "source": [
    "# look at the confidence interval of each coeffecient\n",
    "print result.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we're very confident that there is an inverse relationship between the probability of being admitted and the prestige of a candidate's undergraduate school.\n",
    "\n",
    "In other words, the probability of being accepted into a graduate program is higher for students who attended a top ranked undergraduate college (prestige_1==True) as opposed to a lower ranked school with, say, prestige_4==True (remember, a prestige of 1 is the most prestigious and a prestige of 4 is the least prestigious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## odds ratio\n",
    "Take the exponential of each of the coefficients to generate the odds ratios. This tells you how a 1 unit increase or decrease in a variable affects the odds of being admitted. For example, we can expect the odds of being admitted to decrease by about 50% if the prestige of a school is 2. UCLA gives a more in depth explanation of the odds ratio here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gre           0.002264\n",
       "gpa           0.804038\n",
       "prestige_2   -0.675443\n",
       "prestige_3   -1.340204\n",
       "prestige_4   -1.551464\n",
       "intercept    -3.989979\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                2.5%     97.5%        OR\n",
      "gre         1.000120  1.004418  1.002267\n",
      "gpa         1.166122  4.281877  2.234545\n",
      "prestige_2  0.273692  0.946358  0.508931\n",
      "prestige_3  0.133055  0.515089  0.261792\n",
      "prestige_4  0.093443  0.480692  0.211938\n",
      "intercept   0.001981  0.172783  0.018500\n"
     ]
    }
   ],
   "source": [
    "# odds ratios and 95% CI\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "print np.exp(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging a little deeper\n",
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian which I originally found here.\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "\n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gre       gpa  prestige  intercept  prestige_2  prestige_3  prestige_4  \\\n",
      "0  220.0  2.260000       1.0        1.0           0           0           0   \n",
      "1  220.0  2.260000       2.0        1.0           1           0           0   \n",
      "2  220.0  2.260000       3.0        1.0           0           1           0   \n",
      "3  220.0  2.260000       4.0        1.0           0           0           1   \n",
      "4  220.0  2.453333       1.0        1.0           0           0           0   \n",
      "\n",
      "   admit_pred  \n",
      "0    0.157801  \n",
      "1    0.087056  \n",
      "2    0.046758  \n",
      "3    0.038194  \n",
      "4    0.179574  \n"
     ]
    }
   ],
   "source": [
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))\n",
    "combos\n",
    "# recreate the dummy variables\n",
    "combos.columns = ['gre', 'gpa', 'prestige', 'intercept']\n",
    "combos\n",
    "\n",
    "dummy_ranks = pd.get_dummies(combos['prestige'], prefix='prestige')\n",
    "dummy_ranks.columns = ['prestige_1', 'prestige_2', 'prestige_3', 'prestige_4']\n",
    "dummy_ranks\n",
    "\n",
    "# keep only what we need for making predictions\n",
    "cols_to_keep = ['gre', 'gpa', 'prestige', 'intercept']\n",
    "combos = combos[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "combos\n",
    "train_cols\n",
    "\n",
    "# make predictions on the enumerated dataset\n",
    "combos['admit_pred'] = result.predict(combos[train_cols])\n",
    "print combos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  20, 100],\n",
       "       [  1,  20, 200],\n",
       "       [  1,  30, 100],\n",
       "       [  1,  30, 200],\n",
       "       [  1,  40, 100],\n",
       "       [  1,  40, 200],\n",
       "       [  2,  20, 100],\n",
       "       [  2,  20, 200],\n",
       "       [  2,  30, 100],\n",
       "       [  2,  30, 200],\n",
       "       [  2,  40, 100],\n",
       "       [  2,  40, 200]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartesian( [ [1,2], [20, 30, 40], ['100', '200']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
